# ğŸ› FSDP SFT Trainer Epoch Bug åˆ†æä¸ä¿®å¤

## é—®é¢˜æè¿°

åœ¨è®­ç»ƒä¸­ï¼Œå½“è¾¾åˆ° `save_freq` æ—¶ï¼Œepoch ä¼šç«‹å³åŠ  1ï¼Œç›´åˆ°è¾¾åˆ° `total_epochs` åè®­ç»ƒç»“æŸã€‚

**è®­ç»ƒé…ç½®ï¼š**
```bash
trainer.save_freq=20
trainer.test_freq=20
trainer.total_epochs=10
```

**å®é™…ç°è±¡ï¼š**
- ç¬¬ 20 æ­¥ä¿å­˜åï¼Œepoch ç«‹å³å˜æˆ epoch 2
- epoch å¿«é€Ÿå¢é•¿åˆ° 10ï¼Œç„¶åè®­ç»ƒç»“æŸ
- å¹¶æ²¡æœ‰çœŸæ­£è®­ç»ƒ 10 ä¸ªå®Œæ•´çš„ epoch

## æ ¹æœ¬åŸå› åˆ†æ

### ğŸ” ä¸»è¦é—®é¢˜

åœ¨ `verl/trainer/fsdp_sft_trainer.py` ä¸­çš„ `fit()` æ–¹æ³•ï¼š

**ç¬¬ 722 è¡Œé—®é¢˜ï¼š**
```python
total_training_steps = len(self.train_dataloader) * self.config.trainer.total_epochs
```

è¿™é‡Œè®¡ç®—çš„ `total_training_steps` ä¸ **epoch å¾ªç¯æœºåˆ¶** ä¹‹é—´å­˜åœ¨**ä¸åŒ¹é…**ï¼š

1. **å‡è®¾æƒ…æ™¯ï¼š** 
   - ä½ çš„ dataloader å¤§å° = 20 steps/epoch
   - total_epochs = 10
   - åˆ™ total_training_steps = 20 * 10 = 200 steps

2. **å®é™…å‘ç”Ÿçš„æƒ…å†µï¼š**
   - ç¬¬ 1-20 æ­¥ï¼šå®Œæˆ epoch 0ï¼ˆ20 ä¸ª stepï¼‰
   - ç¬¬ 20 æ­¥ï¼šè§¦å‘ `is_save_step = (global_step % save_freq == 0)` â†’ ä¿å­˜æ£€æŸ¥ç‚¹
   - ç¬¬ 21-40 æ­¥ï¼šè¿›å…¥ epoch 1ï¼ˆdataloader é‡æ–°å¼€å§‹ï¼‰
   - ä¾æ­¤ç±»æ¨...

3. **WHY è¿™æ˜¯ä¸ª BUGï¼š**
   - ä»£ç  **å‡è®¾** åœ¨ç¬¬ 20 æ­¥æ—¶ä»åœ¨ epoch 0 ä¸­ç»§ç»­è®­ç»ƒ
   - ä½†å®é™…ä¸Šï¼Œå¦‚æœ `steps_per_epoch = 20`ï¼Œç¬¬ 20 æ­¥æ­£å¥½æ˜¯ epoch 0 çš„æœ€åä¸€æ­¥
   - ä¸‹ä¸€æ¬¡ dataloader è¿­ä»£ä¼šå¼€å§‹æ–°çš„ epoch
   - è¿™å¯¼è‡´ epoch å¿«é€Ÿæ¨è¿›

### ğŸ¯ çœŸæ­£çš„ Bug ä½ç½®

**ä½ç½®ï¼š** `fsdp_sft_trainer.py` ç¬¬ 749-760 è¡Œ

```python
for epoch in range(start_epoch, self.config.trainer.total_epochs):
    self.train_sampler.set_epoch(epoch=epoch)
    
    for step_in_epoch, data in enumerate(
        tqdm(
            self.train_dataloader,
            initial=global_step % self.steps_per_epoch if epoch == start_epoch else 0,
            total=self.steps_per_epoch,
            desc=f"Epoch {epoch + 1}/{self.config.trainer.total_epochs}",
            disable=rank != 0,
        )
    ):
        global_step += 1
        # ... è®­ç»ƒä»£ç  ...
```

**é—®é¢˜æ ¹æºï¼š**
- å¤–å±‚ epoch å¾ªç¯ä¸å†…å±‚ dataloader å¾ªç¯çš„ **epoch è®¡æ•°ä¸åŒæ­¥**
- å½“ dataloader è€—å°½æ‰€æœ‰æ•°æ®æ—¶ï¼Œä¼šè‡ªåŠ¨å¼€å§‹æ–°çš„ epoch
- ä½†è¿™æ—¶ tqdm æ˜¾ç¤ºçš„ epoch è®¡æ•°å¯èƒ½ä¸å‡†ç¡®

### ğŸ“Š æ•°æ®æµåˆ†æ

```
Global Step | epoch | step_in_epoch | Action
         1  |  0    |      1        | Train
         2  |  0    |      2        | Train
        ...
        20  |  0    |     20        | Train + Save (save_freq=20)
        21  |  1    |      1        | Train (è¿›å…¥ epoch 1)
        22  |  1    |      2        | Train
        ...
        40  |  1    |     20        | Train + Save
        41  |  2    |      1        | Train (è¿›å…¥ epoch 2)
        ...
```

## è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ Aï¼šåŸºäº total_training_steps æ§åˆ¶ï¼ˆæ¨èï¼‰

ä¿®æ”¹ epoch å¾ªç¯é€»è¾‘ï¼Œä½¿ç”¨ `total_training_steps` ä½œä¸ºçœŸå®çš„è®­ç»ƒä¸Šé™ï¼Œè€Œä¸æ˜¯ä¾èµ– epoch æ•°ï¼š

```python
def fit(self):
    rank = self.device_mesh.get_rank()
    
    # ... åˆå§‹åŒ–ä»£ç  ...
    
    global_step = self.resume_global_step
    last_valid_metric = None
    
    # è®¡ç®— total_training_steps
    total_training_steps = len(self.train_dataloader) * self.config.trainer.total_epochs
    
    if self.config.trainer.total_training_steps is not None:
        total_training_steps = self.config.trainer.total_training_steps
    
    self.total_training_steps = total_training_steps
    
    # è®¡ç®—èµ·å§‹ epoch
    start_epoch = global_step // self.steps_per_epoch
    
    train_time = 0
    
    # æ”¹è¿›ï¼šä½¿ç”¨ while å¾ªç¯ï¼Œæ¡ä»¶ä¸º global_step < total_training_steps
    # è€Œä¸æ˜¯ä¾èµ–å¤–å±‚ epoch å¾ªç¯
    epoch = start_epoch
    while global_step < self.total_training_steps:
        self.train_sampler.set_epoch(epoch=epoch)
        
        for step_in_epoch, data in enumerate(
            tqdm(
                self.train_dataloader,
                initial=global_step % self.steps_per_epoch if epoch == start_epoch else 0,
                total=self.steps_per_epoch,
                desc=f"Epoch {epoch + 1}/{self.config.trainer.total_epochs}",
                disable=rank != 0,
            )
        ):
            # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ° total_training_steps
            if global_step >= self.total_training_steps:
                break
            
            global_step += 1
            # ... è®­ç»ƒä»£ç  ...
            
            is_last_step = global_step >= self.total_training_steps
            is_valid_step = global_step % self.config.trainer.test_freq == 0
            is_save_step = global_step % self.config.trainer.save_freq == 0
            
            # ... éªŒè¯å’Œä¿å­˜é€»è¾‘ ...
            
            if is_last_step:
                if rank == 0:
                    print(f"Total time for train steps: {train_time:.2f}s")
                    print(f"Final validation metrics: {last_valid_metric}")
                return
        
        epoch += 1
```

### æ–¹æ¡ˆ Bï¼šæ·»åŠ è°ƒè¯•æ—¥å¿—

åœ¨ä¿å­˜ç‚¹æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼Œä»¥ä¾¿è·Ÿè¸ª epoch å˜åŒ–ï¼š

```python
if is_save_step:
    if rank == 0:
        print(f"[DEBUG] Step {global_step}: epoch={epoch}, steps_in_epoch={step_in_epoch}")
    self.save_checkpoint(step=global_step)
```

## éªŒè¯ä¿®å¤

ä¿®å¤åçš„è¡Œä¸ºåº”è¯¥æ˜¯ï¼š

```
Global Step | epoch | Reason
         1  |  0    | Training
         2  |  0    | Training
        ...
        20  |  0    | Training + Save
        21  |  0    | Training (ä»åœ¨ epoch 0)
        22  |  0    | Training
        ...
        50  |  1    | Training (è¿›å…¥ epoch 1ï¼Œå› ä¸º steps_per_epoch=50)
       100  |  1    | Training + Save (ç¬¬ 2 ä¸ª save)
```

## æ¨èé…ç½®æ£€æŸ¥

æ£€æŸ¥ä½ çš„æ•°æ®é›†å¤§å°æ˜¯å¦ä¸æœŸæœ›çš„ epoch é•¿åº¦åŒ¹é…ï¼š

```python
# åœ¨è®­ç»ƒå¼€å§‹å‰ï¼ŒéªŒè¯ï¼š
print(f"Train dataloader size: {len(self.train_dataloader)} steps")
print(f"Expected steps per epoch: {self.steps_per_epoch}")
print(f"Total steps with {self.config.trainer.total_epochs} epochs: {self.total_training_steps}")
print(f"Save will occur every {self.config.trainer.save_freq} steps")
```

## ç›¸å…³æ–‡ä»¶

- `verl/trainer/fsdp_sft_trainer.py` - åŒ…å« bug çš„ä¸»æ–‡ä»¶
- `verl/utils/dataset/multiturn_sft_dataset.py` - æ•°æ®é›†å®ç°
- `examples/sft/multiturn/run_qwen_multiturn.sh` - è®­ç»ƒè„šæœ¬

## æ€»ç»“

**æ ¸å¿ƒé—®é¢˜ï¼š** epoch å¾ªç¯ä¸ total_training_steps æ§åˆ¶ä¹‹é—´çš„ä¸åŒæ­¥

**æ ¹æœ¬åŸå› ï¼š** ä¾èµ– epoch å¾ªç¯è®¡æ•°è€Œä¸æ˜¯ global_step ä½œä¸ºä¸»è¦ç»ˆæ­¢æ¡ä»¶

**è§£å†³æ–¹æ¡ˆï¼š** ä½¿ç”¨ `global_step >= total_training_steps` ä½œä¸ºä¸»è¦çš„è®­ç»ƒç»ˆæ­¢æ¡ä»¶ï¼Œepoch åªæ˜¯ç”¨äº sampler.set_epoch() å’Œæ—¥å¿—æ˜¾ç¤º








