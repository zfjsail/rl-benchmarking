# Copyright 2024 Bytedance Ltd. and/or its affiliates
# Copyright 2023-2024 SGLang Team
# Copyright 2025 ModelBest Inc. and/or its affiliates
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import os
from typing import Any, Optional
from uuid import uuid4

from verl.utils.reward_score import gsm8k

from .base import BaseInteraction

logger = logging.getLogger(__name__)
logger.setLevel(os.getenv("VERL_LOGGING_LEVEL", "WARN"))


class NDInteraction(BaseInteraction):
    """Interaction for QAQAQA format tasks.
    
    This interaction handles multi-turn Q&A sequences where:
    - Q (Questions) are fixed and provided in the initial prompt
    - A (Answers) are generated by the agent during rollout
    - Multiple Q&A pairs form a single interaction instance
    
    The agent needs to answer all questions in sequence, and the interaction
    evaluates each answer separately. The user (environment) provides the next
    question based on the previous answer.
    
    Example:
        Initial: Q1
        Agent generates: A1
        Environment returns: Reward for A1 + Q2 (if continue, or termination signal)
        Agent generates: A2
        ...
    """

    def __init__(self, config: dict):
        super().__init__(config)
        self._instance_dict = {}

    async def start_interaction(
        self, 
        instance_id: Optional[str] = None, 
        ground_truth: Optional[str] = None,
        evaluation_method: Optional[str] = None,
        **kwargs
    ) -> str:
        """Start a new interaction instance.
        
        Args:
            instance_id: The instance ID
            ground_truth: Ground truth answer for the current Q
            evaluation_method: Method for evaluating the answer (e.g., 'strict', 'flexible')
            **kwargs: Additional arguments for the task
        
        Returns:
            The instance ID
        """
        if instance_id is None:
            instance_id = str(uuid4())
        
        self._instance_dict[instance_id] = {
            "response": "",
            "ground_truth": ground_truth,
            "reward": 0.0,
            "evaluation_method": evaluation_method or "strict",
            "qa_history": [],  # Track all Q&A pairs in this instance
        }
        return instance_id

    async def generate_response(
        self, 
        instance_id: str, 
        messages: list[dict[str, Any]], 
        **kwargs
    ) -> tuple[bool, str, float, dict]:
        """Generate response and evaluate the agent's answer.
        
        This method:
        1. Extracts the latest assistant response from messages
        2. Evaluates the response against ground truth
        3. Decides whether to continue (provide next question) or terminate
        
        Args:
            instance_id: The instance ID
            messages: The conversation messages
            **kwargs: Additional arguments including:
                - provide_next_q: Whether to provide the next question
                - next_q_content: Content of the next question (if provided)
        
        Returns:
            Tuple of (should_terminate, response_content, reward, metadata_dict)
                - should_terminate: Whether the interaction should end
                - response_content: The content to add to the conversation
                - reward: The reward for this answer
                - metadata_dict: Additional metadata
        """
        # Extract the latest assistant response
        content = ""
        for i in range(len(messages) - 1, -1, -1):
            item = messages[i]
            if item.get("role") == "assistant":
                content = item.get("content")
                break

        self._instance_dict[instance_id]["response"] = content

        # Calculate reward for this answer
        reward = await self.calculate_score(instance_id)
        
        # Store Q&A pair
        self._instance_dict[instance_id]["qa_history"].append({
            "question": self._instance_dict[instance_id].get("current_question", ""),
            "answer": content,
            "reward": reward,
        })

        # Determine whether to continue or terminate
        should_terminate = kwargs.get("should_terminate", False)
        provide_next_q = kwargs.get("provide_next_q", True)
        next_q_content = kwargs.get("next_q_content", None)
        
        if should_terminate or not provide_next_q:
            # Terminate the interaction
            response = "The interaction has been completed."
            should_terminate_sequence = True
        else:
            # Continue with next question
            if next_q_content is None:
                # No more questions, terminate
                response = "No more questions available."
                should_terminate_sequence = True
            else:
                # Provide the next question
                response = next_q_content
                should_terminate_sequence = False
                # Store the current question for the next evaluation
                self._instance_dict[instance_id]["current_question"] = next_q_content

        return should_terminate_sequence, response, reward, {
            "qa_history": self._instance_dict[instance_id]["qa_history"],
        }

    async def calculate_score(self, instance_id: str, **kwargs) -> float:
        """Calculate the score for the current answer.
        
        Uses the evaluation method specified in the instance.
        For GSM8K-style tasks, uses the standard GSM8K scoring function.
        """
        instance = self._instance_dict[instance_id]
        ground_truth = instance["ground_truth"]
        response = instance["response"]
        evaluation_method = instance.get("evaluation_method", "strict")
        
        if evaluation_method == "strict":
            return gsm8k.compute_score(
                response,
                ground_truth,
                method="strict",
                format_score=0.0,
                score=1.0,
            )
        else:
            # Support other evaluation methods if needed
            return gsm8k.compute_score(
                response,
                ground_truth,
                method="flexible",
                format_score=0.0,
                score=1.0,
            )

    async def finalize_interaction(self, instance_id: str, **kwargs) -> None:
        """Finalize the interaction and clean up resources."""
        if instance_id in self._instance_dict:
            del self._instance_dict[instance_id]
